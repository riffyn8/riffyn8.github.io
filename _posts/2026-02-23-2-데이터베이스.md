---
layout: post
title: 2.데이터베이스
date: 2026-02-23
categories: [자격증, 정보처리기사]
sitemap: false
math: true
media_subpath: /assets/img/posts/
comments: false
---

## 1) 논리 데이터베이스 설계
### 스키마(Schema)
데이터베이스의 구조와 제약 조건에 관한 전반적인 명세를 기술한 것을 의미
- **외부(External) 스키마**: 사용자나 응용 프로그래머가 보는 개인적 관점(여러 개가 존재)
- **개념(Conceptual) 스키마**: DB 전체의 논리적 구조(전체적인 관점. 딱 하나만 존재)
- **내부(Internal) 스키마**: 물리적 저장 장치 관점(저장 방식, 인덱스 등)

### 데이터베이스 설계 순서
`요구조건 분석 → 개념적 설계 → 논리적 설계 → 물리적 설계 → 구현`

1. **개념적 설계(개념 모델링)**
   - 정보 모델링을 통해 현실 세계의 인식을 추상적 개념 세계로 표현하는 단계
   - E-R 다이어그램 작성, 트랜잭션 모델링 수행, 개념 스키마 설계
   - 특정 DBMS에 독립적이다.
2. **논리적 설계(논리 모델링)**
   - 개념적 구조를 목표 DBMS가 지원하는 논리적 데이터 구조로 변환하는 단계
   - 개념적 모델을 논리적 데이터 모델(관계, 망, 계층형)로 변환(Mapping Rule)
   - 데이터의 중복을 제거하고 일관성을 확보하기 위해 정규화 수행
   - 트랜잭션 인터페이스 설계, 논리 스키마 설계 및 평가/정제
   - 특정 DBMS에 종속적이다.
3. **물리적 설계(물리 모델링)**
   - 논리적 구조를 실제 저장 장치에 저장하기 위한 물리적 구조로 변환하는 단계
   - 인덱스 및 파티션 설계 
   - 저장 레코드의 양식, 물리적 순서, 접근 경로 설정 
   - 반정규화 수행 
   - 트랜잭션 세부 작성 및 응답 시간 최적화 
   - 하드웨어 및 성능에 밀접하게 연관 
   - 저장 공간의 효율성과 트랜잭션 처리량 고려 필요

### 데이터 모델링
현실 세계의 정보들을 컴퓨터에 표현하기 위해 단순화, 추상화하여 체계적으로 표현한 개념적 모형
- **구성요소**: `개체(Entity), 속성(Attribute), 관계(Relationship)`
- **표시할 요소**
  - **구조(Structure)**: DB에 논리적으로 표현될 데이터 객체들 간의 관계 (정적)
  - **연산(Operation)**: DB에 저장된 데이터를 처리하는 작업을 정의 (동적)
  - **제약 조건(Constraint)**: DB에 저장될 수 있는 데이터의 정확성을 위한 허용 규칙

### E-R 다이어그램
피터 첸에 의해 제안되었음. 개체 타입과 이들 간의 관계 타입을 이용해 현실 세계를 개념적으로 표현
![e-r다이어그램](erdiagram.png)

### 확장 E-R 다이어그램
기존 E-R 모델에 객체지향적인 개념을 추가하여 더 복잡한 데이터 관계를 표현할 수 있도록 확장한 모델
- **일반화(Generalization)**: 하위 개체들의 공통적인 특성을 모아 상위 개체를 만드는 과정 (Bottom-up)
- **특수화(Specialization)**: 상위 개체를 구체적인 기준에 따라 하위 개체로 나눈 과정(Top-down)
- **슈퍼타입**: 공통 속성을 가진 상위 개체
- **서브타입**: 슈퍼타입의 속성을 물려받으면서 자신만의 고유한 특성을 가진 하위 개체
- **집단화(Aggregation)**: 연관된 개체들을 묶어서 하나의 상위 개체로 취급하는 것
- **분해화(Decomposition)**: 하나의 큰 시스템이나 복잡한 개체를 더 작은 단위로 쪼개는 과정
- **분류화(Classification)**: 공통된 속성을 가진 객체들을 모아 타입을 정의하는 것
- **인스턴스화**: 설계된 개체타입에 실제 값을 넣어 실제 데이터를 만드는 과정

### DBMS
사용자와 데이터베이스 사이에서 데이터를 정의하고 분석하기 위해 상호작용을 하는 시스템

### 시스템 카탈로그
데이터베이스의 모든 객체에 대한 정보를 담고 있는 시스템 데이터베이스
- **메타 데이터(Meta Data)**: 데이터에 관한 데이터가 저장되어 있음
- **데이터 사전(Data Dictionary)**: 시스템 카탈로그를 데이터 사전이라고도 부름
- 사용자가 직접 내용을 수정할 수 없으며, DBMS가 자동으로 갱신한다.
- 사용자는 SELECT 문을 사용하여 조회만 할 수 있다.

### DB 시스템 유형
- **파일시스템**: 자료에 쉽게 접근할 수 있도록 논리적인 파일 단위로 관리하는 일반적인 데이터 관리 시스템
  - **FAT**: 간단한 구조, 파일 크기 제한, 데이터 보호 기능 부족
  - **NTFS**: FAT에서 발전. 고성능, 고용량, 고보안
- **RDBMS**: 데이터를 테이블 구조로 모델링하여 관리하는 형태의 대표적인 DB 시스템. 테이블을 기준으로 상호 간의 관계를 설정

### RDBMS 용어
- **개체(Entity)**: 현실 세계의 개념이나 대상을 DB로 표현하고자 하는 논리적인 표현 단위
- **속성(Attribute)**: 열(Column)에 해당. 개체를 구성하는 고유 특성. 데이터의 가장 작은 논리적 단위 
- **도메인(Domain)**: 하나의 속성값이 가질 수 있는 모든 원자 값의 집합
- **튜플(Tuple)**: 행(Row)에 해당. 속성의 모임. 릴레이션 인스턴스라고도 한다.
- **릴레이션(Relation)**: 개체에 관한 데이터를 속성과 튜플로 구성된 2차원 테이블의 구조로 표현한 것
- **차수(Degree)**: 속성의 개수
- **기수(Cardinality)**: 튜플의 개수
  - 모든 속성이 제한된 수의 도메인을 가질 때, 릴레이션의 최대 기수는 각 도메인의 곱과 같다.


### 키(Key)
- **슈퍼키(Super Key)**: 튜플을 유일하게 식별할 수 있는 하나 이상의 속성의 집합. 유일성만 만족
- **후보키(Candidate Key)**: 릴레이션에 존재하는 모든 튜플에 대해 유일성과 최소성을 모두 만족
- **기본키(Primary Key)**: 후보키들 중 튜플의 식별을 위해 지정된 속성. 중복과 Null 값을 가질 수 없음
- **대체키(Alternate Key)**: 기본키로 지정된 속성을 제외한 후보키
- **외래키(Foreign Key)**: 관계된 다른 릴레이션의 기본키를 참조하는 속성

### 정규화(Normalization)
데이터의 중복을 최소화하고 불일치를 방지하기 위해 무결성을 유지하며 테이블을 분해하는 과정
![정규화](normalization.png)

- **함수적 종속**: 데이터들이 어떤 기준값에 의해 종속되는 것을 의미. X → Y (Y가 X에게 종속)
- **부분 함수 종속**: 기본키가 아닌 일부 속성에만 종속되는 현상
- **이행적 종속**: X → Y이고, Y → Z일 때, X → Z를 만족하는 관계

> 1NF는 원자값을 가지기 위한 정규형으로, 분할하는 과정에서 기본키가 없는 테이블이 생성될 수 있음

### 이상(Anomaly)
정규화를 거치지 않으면 데이터베이스 내에 데이터들이 불필요하게 중복되어 릴레이션 조작 시 예기치 못한 현상이 발생하는 것
- 종류: 삽입, 삭제, 갱신 이상

### 무결성(Integrity)
데이터베이스에 저장된 값의 정확성, 유효성, 일관성을 보장하는 성질 (성능 향상과는 관련 x)
- **도메인 무결성**: 특정 속성 값은 정의된 범위 내의 값이어야 한다
- **개체 무결성**: 기본키는 Null과 중복값을 가질 수 없다
- **참조 무결성**: 외래키 값은 참조하는 테이블의 기본키와 같거나 Null이어야 한다.

### 관계대수
원하는 정보와 그 정보를 어떻게(How) 유도하는가를 정의하는 <u>절차적 언어</u>
- 순수 관계 연산자: Select, Project, Join, Division
- 일반 집합 연산자: 합집합, 교집합, 차집합, 교차곱

### 순수 관계 연산자
- **Select($\sigma$)**: 릴레이션에서 조건에 맞는 행(Tuple)을 선택 (`WHERE` 절)
- **Project($\pi$)**: 릴레이션에서 필요한 열(Attribute)만 추출 (`SELECT` 절)
- **Join($\bowtie$)**: 공통 속성을 중심으로 두 개의 릴레이션을 합침 (`JOIN` 문)
- **Division($\div$)**: 속성 B의 모든 조건을 만족하는 속성 A를 추출

### 일반 집합 연산자
- **합집합(Union, $\cup$)**: 두 릴레이션의 모든 튜플을 합침. $A + B$ (중복 제거)
- **교집합 (Intersection, $\cap$)**: 두 릴레이션에 공통으로 존재하는 튜플만 추출. $A \cap B$
- **차집합 (Difference, $-$)**: 첫 번째 릴레이션에는 있고 두 번째에는 없는 튜플 추출. $A - B$
- **교차곱 (Cartesian Product, $\times$)**
  - 두 릴레이션의 모든 튜플을 가능한 모든 조합으로 합침. $A \times B$
  - 결과 레코드 수는 두 릴레이션의 기수(Cardinality)의 곱, 속성 수는 차수(Degree)의 합이다.

### 관계해석
원하는 정보가 무엇(What)인지에 대해 정의하는 <u>비절차적 언어</u> (관계대수보다 높은 수준의 언어)
- **전칭 정량자**: `∀` 가능한 모든 튜플에 대하여(For All)
- **존재 전량자**: `∃`하나라도 일치하는 튜플이 있음(There Exists)
- 그 외: AND(`^`), OR(`∨`), NOT(`¬`) 

---

## 2) 물리적 설계
### 클러스터링
데이터 엑세스 효율을 높이기 위해 동일한 성격의 데이터를 물리적으로 동일한 블록에 저장하는 방식

### 파티셔닝
대용량의 테이블이나 인덱스를 관리하기 쉽도록 작은 단위로 분할하는 기법
- **범위(Range) 분할**: 연속된 범위를 기준으로 데이터를 분할
- **해시(Hash) 분할**: 해시 함수를 적용하여 데이터를 균등하게 분산. 데이터의 양을 예측하기 어려울 때 사용
- **조합(Composite, 복합) 분할**: 범위 분할로 먼저 나눈 뒤, 해시 분할로 나눔
- **목록(List) 분할**: 특정 값들의 목록을 기준으로 데이터를 분할

### 스토리지
단일 서버로 처리하기 힘든 대용량 데이터를 저장하기 위해 여러 저장 장치를 하나의 집합으로 연결한 시스템
- **DAS**: 서버와 저장 장치를 전용 케이블로 직접 연결
- **NAS**: 이더넷(LAN)을 통해 서버와 저장 장치를 연결
- **SAN**: DAS+NAS. 서버와 저장장치를 연결하는 전용 네트워크를 별도로 구성

### CRUD 매트릭스
CRUD 프로세스와 테이블의 영향도를 테이블 형식으로 표현한 것

### 반정규화(Denormalization)
성능 향상과 관리 효율성을 위해 정규화된 데이터 모델을 의도적으로 통합, 중복, 분리하는 데이터 모델링 기법
- **중복 테이블 추가**: 특정 범위의 데이터가 자주 처리되거나 많은 양의 데이터를 자주 처리하는 경우 수행
- **중복 속성 추가**: 데이터를 조회하는 경로를 단축하기 위해 수행
- **테이블 분할**: 특정 컬럼의 사용 빈도가 높은 경우에 수행 (수직-컬럼 기준, 수평-속성 기준)
- **테이블 통합**: 두 테이블을 조인해서 조회하는 경우가 많은 경우에 수행

### View
사용자에게 접근이 허용된 자료만을 제한적으로 보여주기 위해 하나 이상의 기본테이블로부터 유도된 이름을 가지는 가상 테이블
- 뷰의 구조를 변경할 수는 없다.
- 제약이 있지만 데이터를 수정할 수 있다
- 인덱스를 가질 수 없다

### Index
데이터 레코드를 빠르게 접근하기 위해 <키, 포인터> 쌍으로 구성되는 데이터 구조
- 데이터가 저장된 물리적 구조와 밀접한 관계가 있으며, 이에 대한 접근 방법을 제공한다.
- 조회나 조인에 사용되는 컬럼에 사용 시 검색 속도가 향상된다
- 인덱스를 저장하기 위한 공간이 필요하며 인덱스가 너무 많으면 오버헤드가 발생한다.
- 분포도가 좋을수록(중복이 적을수록) 인덱스의 효율이 좋다
- **클러스터드 인덱스**: 데이터 행의 순서가 인덱스 순서와 동일 (테이블 당 하나만 가능)
- **넌클러스터드 인덱스**: 별도 인덱스 페이지를 생성한다 (여러 개 생성 가능, 클러스터드 보단 속도가 느림)

---

## 3) 데이터베이스 운영 및 관리
### 트랜잭션
데이터베이스에서 하나의 논리적 기능을 수행하기 위한 작업의 단위이자, 한꺼번에 모두 수행되어야 할 연산의 집합
- **원자성(Atomicity)**: 모두 반영되거나, 전형 반영되지 않아야 한다
- **일관성(Consistency)**: 실행 완료 후에도 데이터베이스 상태가 일관되어야 한다
- **격리성(Isolation, 고립성)**: 둘 이상의 트랜잭션이 동시에 실행될 때 서로 끼어들 수 없음
- **영속성(Durability, 지속성)**: 성공적으로 완료된 결과는 영구적으로 보존되어야 함

#### 트랜잭션 상태
- **활동(Active)**: 트랜잭션이 현재 실행 중인 첫 번째 상태
- **부분 완료(Partially Committed)**: 마지막 연산까지 끝났지만, 최종 결과를 DB에 물리적으로 저장하기 직전의 상태
- **완료(Committed)**: 트랜잭션이 성공적으로 종료되어 Commit 연산을 마친 상태 (영구 저장)
- **실패(Failed)**: 실행 도중 오류가 발생하여 중단된 상태
- **철회(Aborted)**: 트랜잭션에 실패하여 Rollback 연산을 수행한 상태 (이전 상태로 복구)
- **Completed**: 이미 커밋이나 롤백을 실행했으니 더이상 커밋과 롤백을 하지말라는 오류

### 병행제어(Concurrency Control, 동시성 제어)
여러 개의 트랜잭션이 동시에 실행될 때 데이터베이스의 일관성을 해치지 않도록 제어하는 기술

### 병행제어의 문제점
- **갱신 분실(Lost Update)**: 갱신 결과의 일부가 없어짐
- **모순성(Inconsistency)**: 두 트랜잭션이 병행 수행될 때, 원치 않는 자료를 이용함으로써 발생
- **연쇄 복귀(Cascading Rollback)**: 병행 수행되던 트랜잭션들 중 어느 하나에 문제가 생겨 롤백하는 경우 다른 트랜잭션도 함께 롤백되는 현상
- **비완료 의존성(Uncommitted Dependency)**: 하나의 트랜잭션 수행이 실패하고 회복되기 전 다른 트랜잭션이 참조하는 현상

### 로킹
트랜잭션이 갱신 중인 데이터를 다른 트랜잭션이 접근하지 못하도록 잠그는 것
- **로킹 단위 ↑**: 로크 수 ↓ 병행성 수준 ↓
- **로킹 단위 ↓**: 로크 수 ↑ 병행성 수준 ↑ (but, 오버헤드도 증가)
- **타임 스탬프(Time Stamp)**: 트랜잭션에 부여된 시간표 순서대로 데이터에 접근 
- **낙관성 병행 제어(Optimistic Concurrency Control)**: 트랜잭션 종료 시에 일괄적으로 검사
- **다중 버전 병행 제어(MVCC)**: 데이터의 버전(SnapShot)을 관리하여 읽기와 쓰기 충돌을 줄이는 방식

### 회복
트랜잭션들을 수행하는 도중에 장애가 발생하여 데이터베이스가 손상되었을 때 손상되기 이전의 정상 상태로 복구하는 작업
- **Undo**: 장애 발생 시 완료되지 않은 트랜잭션이 작업한 내용을 취소하여 이전 상태로 되돌리는 것
- **Redo**: 장애 발생 전 완료된 트랜잭션의 내용을 로그를 이용해 다시 실행하여 DB에 반영

#### 로그를 이용한 회복 기법
- **즉시(Immediate) 갱신**: 트랜잭션 수행 중 변경 내용을 즉시 DB에 반영. 장애시 Redo와 Undo 모두 수행
- **지연(Deferred) 갱신**: 트랜잭션 완료 전까지 변경 내용을 로그에만 저장하고 완료 후 DB에 반영. 장애시 Redo만 수행

#### 로그를 사용하지 않은 회복 기법
- **검사점(Checkpoint)**: 주기적으로 체크포인트를 설정하여, 가장 최근의 검사점 이후 작업에 대해서만 회복을 수행
- **그림자 페이지(Shadow Paging)**: 로그를 사용하지 않고, 복제된 그림자 페이지를 별도로 보관하여 장애 발생 시 이를 현재 페이지와 교체함으로써 데이터를 복구

---

## 4) 분산 데이터베이스
### 분산 데이터베이스
물리적으로는 여러 곳에 흩어져 있지만, 사용자는 마치 하나의 논리적 시스템처럼 사용할 수 있게 관리되는 데이터베이스
- **위치 투명성(Location Transparency)**: 데이터의 실제 저장 위치를 몰라도 논리적인 이름만으로 접근 가능
- **중복 투명성(Replication Transparency)**: 데이터가 여러 곳에 복제되어 있어도 사용자는 마치 하나의 데이터만 있는 것처럼 사용
- **분할 투명성(Fragmentation Transparency**: 하나의 논리적 릴레이션이 여러 단편으로 나뉘어 저장되어도 사용자는 이를 인식하지 못함
- **병행 투명성(Concurrency Transparency)**: 여러 트랜잭션이 동시에 실행되어도 결과의 일관성이 유지
- **장애 투명성(Failure Transparency)**: 특정 지역의 서버에 장애가 발생해도 서비스를 사용할 수 있음
- **구성 요소**: 분산 처리기, 분산 DB, 통신 네트워크, 분산 트랜잭션

---

## 5) SQL
### 데이터 정의어(DDL)
데이터 조작을 위한 공간을 정의, 수정, 변경하는 언어. DBA가 사용한다.

#### CREATE
데이터베이스 객체(DB, TABLE, INDEX, VIEW)를 생성

```
CREATE TABLE table_name(
  컬럼명 데이터유형 [DEFAULT 기본값] [컬럼 제약 조건],
  컬럼명 데이터유형,
  ...,
  [CONSTRAINT <테이블 제약 조건명> <테이블 제약 조건>]                     
);
```
{: file="테이블 생성" }

##### 제약 조건 종류
- **NOT NULL**: `NULL`값을 허용하지 않음. 컬럼 레벨에서만 선언 가능
- **UNIQUE (필드명)**: 유일키 정의(식별자 정의)
- **CHECK (조건)**: 컬럼에 허용되는 값을 제한 (도메인 값 설정)
- **PRIMARY KEY (컬러명)**: 기본키 설정
- 외래키 설정
  1. `컬럼명 데이터유형 REFERENCES 참조테이블(참조컬럼)`: 컬럼 레벨에서 선언
  2. `FOREIGN KEY (컬럼명) REFERENCES 참조테이블(참조컬럼) [참조 옵션]`: 테이블 레벨에서 선언

##### 참조 옵션
외래키 설정 시 부모 테이블(참조 테이블)의 데이터가 변경될 때 자식 테이블의 데이터를 제어하여 참조 무결성을 유지하는 옵션
- **참조 동작 (`ON [DELETE | UPDATE]`)**: 부모 테이블의 데이터가 삭제/수정될 때 자식 테이블의 동작을 설정
- **`SET [DEFAULT | NULL]`**: 부모 데이터 삭제/수정 시, 자식 테이블의 외래키 값을 변경하는 설정
- **CASCADE(연쇄)**: 부모 데이터 삭제/수정 시, 자식 테이블의 데이터도 함께(연쇄적으로) 삭제/수정된다
- **RESTRICT(제한)**: 자식 테이블에서 참조하고 있는 데이터가 존재하면, 부모 테이블의 원본 데이터 삭제/수정을 금지(제한)한다.

#### ALTER
이미 생성된 테이블의 구조를 변경할 때 사용
```
#컬럼 추가 (ADD)
ALTER TABLE 테이블명 ADD 컬럼명 데이터유형 [위치옵션];
#FIRST: 첫 컬럼 앞에 추가
#AFTER (컬럼명): 특정 컬럼 뒤에 추가

#컬럼 데이터 유형 변경 (MODIFY)
ALTER TABLE 테이블명 MODIFY 컬럼명 데이터유형;

#컬럼명 변경 (RENAME COLUMN ~ TO)
ALTER TABLE 테이블명 RENAME COLUMN 원본컬럼명 TO 변경컬럼명;

#컬럼 삭제 (DROP)
ALTER TABLE 테이블명 DROP 컬럼명;

#제약조건
ALTER TABLE 테이블명 {옵션} CONSTRAINT 제약조건명 [제약조건];
#ADD: 제약조건 추가
#ENDABLE: 제약조건 활성화
#DISABLE: 제약조건 비활성화
#DROP: 제약조건 삭제
```

#### DROP
데이터베이스 객체를 완전히 삭제할 때 사용
```
DROP 객체유형 객체명 [삭제옵션];
#예: DROP TABLE 테이블명 
#삭제옵션: CASCADE, RESTRICT
```

#### TRUNCATE
테이블의 <u>구조를 유지</u>하는 상태에서 <u>모든 데이터를 완전 삭제</u>
```
TRUNCATE TABLE 테이블명;
```

#### VIEW 
```
#뷰 생성
CREATE [OR REPLACE] VIEW 뷰명[(컬럼명[, 컬럼명, ...])]
AS SELECT문
[WITH CHECK OPTION]
[WITH READ ONLY];

#뷰 삭제
DROP VIEW 뷰명;

#뷰 조회
SELECT * FROM 뷰명; 
```
- **OR REPLACE**: 같은 이름의 뷰가 있으면 새로운 정의로 대체
- **WITH CHECK OPTION**: 뷰의 `WHERE` 조건에 어긋나는 변경을 실행할 수 없도록 제한
- **WITH READ ONLY**: 뷰를 통해 데이터를 변경하는 것을 막고 조회만 가능하도록 설정

#### INDEX
```
#인덱스 생성
CREATE [UNIQUE] [CLUSTERED | NONCLUSTERED] INDEX 인덱스명 
ON 테이블명 (컬럼명 [ASC | DESC], ...);

#인덱스 삭제
ALTER TABLE 테이블명 DROP INDEX 인덱스명;

#인덱스 변경
ALTER [UNIQUE] INDEX 인덱스명 ON 테이블명 (컬럼명);

#인덱스 조회
SHOW INDEX FROM 테이블명;
```

### 데이터 조작어(DML)
사용자가 DBMS를 통해 데이터베이스를 조작하기 위한 인터페이스를 제공하는 언어

#### INSERT
테이블에 새로운 데이터를 삽입
```
INSERT INTO 테이블명(컬럼1, 컬럼2, ...) VALUES(값1, 값2, ...);
```

#### UPDATE
테이블에 저장된 기존 데이터를 수정
```
UPDATE 테이블명 SET 컬럼명=값 [WHERE 조건];
```

#### DELETE
테이블의 구조는 남겨두고 <u>조건에 맞는 데이터를 삭제</u>
```
DELETE FROM 테이블명 [WHERE 조건];
```

#### SELECT
테이블에서 원하는 데이터를 검색하여 출력
- **실행 순서**: `FROM → WHERE → GROUP BY → HAVING → SELECT → ORDER BY`
```
SELECT [PREDICATE] [테이블명.]속성명 [AS 별칭] 
[, 그룹함수(속성명) [AS 별칭]]
[, WINDOW함수 OVER (PARTITION BY 컬럼 ORDER BY 컬럼) [AS 별칭]]
FROM 테이블명
[WHERE 조건]
[GROUP BY 속성명]
[HAVING 조건]
[ORDER BY 속성명 [ASC | DESC]]
```

##### PREDICATE
SELECT문에서 검색 결과 튜플(행)의 중복 여부를 결정하는 옵션
- **ALL**: 중복 포함 모든 튜플 검색(기본값, 생략 가능)
- **DISTINCT**: 중복된 튜플은 제거하고 하나만 검색
- **DISTINCTROW**: 튜플 전체를 대상으로 중복 제거

##### WHERE 절 조건
비교 연산자, 논리 연산자, LIKE 연산자 사용 가능
- LIKE: 특정 문자 패턴을 포함하는 문자열을 검색할 때 사용 
  - `%`: 글자 수 제한 없는 모든 문자 검색
  - `_`: 임의의 문자 하나
 
>- 학생 테이블에서 이름이 김으로 시작하는 3글자 이름만 찾기 `SELECT * FROM STUDENT WHERE 학생이름 LIKE '김__'`
>- 이름이 김으로 시작하는 모든 이름 찾기 `SELECT * FROM STUDENT WHERE 학생이름 LIKE '김%'`

#### 집계 함수
집계 함수에 대한 조건은 HAVING 절에서만 설정할 수 있다. 기본적으로 NULL 값을 제외하고 계산 한다.
- **COUNT(컬럼명)**: 검색된 행(레코드)의 개수 (COUNT는 NULL을 포함한 전체 행 개수를 계산)
- **SUM(컬럼명)**: 합계
- **AVG(컬럼명)**: 평균
- **MAX(컬럼명)** / **MIN(컬럼명)**: 최대값/최소값
- **STDDEV(컬럼명)**: 표준 편차
- **VARIANCE(컬럼명)**: 분산

#### 그룹 함수
- **ROLLUP()**: 소그룹부터 전체 합계까지 계층적 순서로 중간 집계를 생성
- **CUBE()**: 결합 가능한 모든 항목의 조합에 대해 다차원 집계를 생성
- **GROUPING SETS()**: 특정 항목들에 대해서만 개별적으로 그룹화된 결과를 출력
- **GROUPING()**: 소계가 개산된 행인지 판별하여 0또는 1을 반환

#### WINDOW 함수
순위나 집계 수치를 행의 손실 없이 나열해주는 함수
1. 문법 구성 요소
   - **PARTITION BY**: 전체 집합을 기준에 따라 소그룹으로 나눔
   - **ORDER BY**: 어떤 항목을 기준으로 순위를 결정할지 결정
   - **OVER**: WINDOW 함수에서 반드시 사용해야 하는 키워드
   - 전체 순위가 필요하면 ORDER BY, 그룹별 순위가 필요하면 PARTITION BY 사용
2. 순위 함수
   - **RANK()**: 공동 순위만큼 건너뜀
   - **DENSE_RANK()**: 공동 순위 무관 연속
   - **ROW_NUMBER()**: 중복 상관없이 고유 번호를 부여
3. 행 이동 함수
   - **LAG(컬럼명)**: 현재 행 기준으로 이전 행의 값 가져오기
   - **LEAD(컬럼명)**: 현재 행 기준으로 다음 행의 값 가져오기 

> `SUM(급여) OVER (ORDER BY 직급 DESC)` 
> : 직급을 내림차순으로 정렬하여, 위에서 아래로 급여의 누적 합계를 구함

> `SUM(급여) OVER (PARTITION BY 부서 ORDER BY 직급 DESC)`
> : 부서별로 그룹을 나누고, 그 안에서 직급별로 정렬하여 부서별 누적 합계를 구함

#### 하위 질의(서브 쿼리)
메인 쿼리에 포함된 또 하나의 쿼리. 일반적으로 수행 결과가 오직 하나의 행으로만 반환된다.
- 다중 행 서브 쿼리를 사용하면 여러 행으로 반환된다 (IN, ANY, SOME, ALL, EXISTS)
- **IN**: 서브쿼리의 결과 중 어느 하나라도 일치하면 참
- **ANY** / **SOME**: 서브쿼리의 결과 중 하나라도 만족하면 참
- **ALL**: 서브 쿼리의 결과 모두를 만족
- **EXISTS**: 서브쿼리의 결과가 한 건이라도 존재하면 참

#### 집합 연산자 
두 개 이상의 SELECT 문 결과를 하나로 결합하는 연산
- **UNION**: 중복된 행을 제거하고 합침
- **UNION ALL**: 중복된 행을 포함하여 모든 결과를 합침

### 데이터 제어어(DCL)
사용자의 데이터 접근 통제와 병행 수행을 위한 제어 언어

#### GRANT
특정 사용자 및 그룹에게 권한을 부여
```
#특정 데이터를 만질 수 있는 권한
GRANT 권한_리스트 ON 대상_객체 TO 사용자 [WITH GRANT OPTION];

# 사용자의 등급을 설정
GRANT 사용자등급 TO 사용자_ID_리스트 [IDENTIFIED BY 암호];
```
- **권한_리스트**: ALL, SELECT, INSERT, UPDATE, DELETE 등 
- **대상_객체**: 테이블명, 뷰 이름 등 
- **WITH GRANT OPTION**: 부여받은 권한을 다른 사용자에게 재부여 할 수 있음. 권한이 회수 당하면, 재부여한 권한도 함께 연쇄적으로 취소 됨
- **WITH ADMIN OPTION**: 권한을 받은 사용자의 권한이 회수되어도, 재부여된 사용자의 권한은 취소되지 않음
- **사용자등급**: DBA(모든 권한), RESOURCE(객체 생성 권한), CONNECT(접속 권한)

> 시스템 권한(CREATE TABLE, CREATE SESSION)은 `ON`을 사용하지 않음 → `GRANT CREATE TABLE TO USER` <br/>
> 객체 권한(DML 관련)을 설정할 때 `ON`을 사용

#### REVOKE
부여된 권한을 회수한다
```
# 특정 데이터 권한 회수
REVOKE 권한_리스트 ON 대상_객체 FROM 사용자 [CASCADE | RESTRICT];

# 사용자 등급 회수
REVOKE 사용자등급 FROM 사용자_ID_리스트;
```
- **CASCADE**: 권한을 부여받았던 사용자가 다른 사용자에게 연쇄적으로 부여한 권한까지 모두 함께 취소
- **RESTRICT**: 권한 취소 시, 다른 사람에게 부여된 권한이 연결되어 있으면 회수를 거부

#### COMMIT
트랜잭션의 작업이 성공적으로 완료되었음을 확정하고 데이터베이스에 영구적으로 반영

#### ROLLBACK
트랜잭션 작업 중 오류가 발생했을 때, 마지막 commit 시점이나 특정 체크포인트로 되돌림

#### 체크포인트
- **SAVEPOINT**: 사용자가 SQL로 직접 명시
- **CHECKPOINT**: DBMS가 주기적으로 자동 수행

### JOIN
두 개 이상의 테이블을 공통된 컬럼을 기준으로 결합하여 하나의 결과셋을 만드는 연산

#### 내부 조인(Inner Join)
교집합. 조건에 일치하는 행만 추출
- **등가 조인 (Equi Join)**: `=` 연산자를 사용해 조건이 정확히 일치하는 데이터를 연결
- **비등가 조인 (Non-Equi Join)**: `>`, `<`, `BETWEEN` 등 `=` 이외의 연산자로 데이터를 연결
- **자연 조인 (Natural Join, $\Join$)**: 이름과 타입이 같은 컬럼을 자동으로 찾아 조인하며, 중복된 컬럼은 제거하고 한 번만 표시

#### 외부 조인(Outer Join)
합집합. 조건에 맞지 않는 행도 포함하여 결과를 출력 (빈 곳은 NULL 처리)
- **Left Outer Join, $⟕$**: 왼쪽 테이블의 모든 행을 유지하며 오른쪽과 연결
- **Right Outer Join, $⟖$**: 오른쪽 테이블의 모든 행을 유지하며 왼쪽과 연결
- **Full Outer Join**: 양쪽 테이블의 모든 데이터를 합쳐서 보여줌

#### 주요 특수 조인 및 연산 방식
- **세타 조인 (Theta Join, $\theta$)**: 비교 연산자를 사용하는 가장 일반적인 조인 형태.(등가, 비등가 조인의 총칭)
- **교차 조인 (Cross Join, $\times$)**: 두 테이블의 모든 행을 조합 (카테시안 곱)
- **셀프 조인 (Self Join)**: 하나의 테이블 내에서 자기 자신과 조인
- **세미 조인 (Semi Join, $\ltimes$)**: 조인된 결과 중 메인 테이블의 데이터만 추출하여 중복을 제거
- **안티 조인 (Anti Join)**: 조인 조건에 맞지 않는 데이터만 메인 테이블에서 추출

### 절차형 SQL
- **프로시저(Procedure)**: 특정 기능을 수행하기 위해 미리 작성하여 데이터베이스에 저장해 둔 SQL 문의 집합
- **사용자 정의 함수(User Defined Function)**: 프로시저와 유사하게 SQL을 모듈화한 것이지만, 종료 시 반드시 값을 반환해야 한다.
- **트리거(Trigger)**: 데이터베이스의 테이블에 특정 이벤트가 발생할 때마다 자동으로 실행되도록 설정된 절차형 SQL

---

## 6) 자료구조
### 자료구조 종류
- **선형 구조**: `배열, 선형 리스트(연속, 연결), 스택, 큐, 데크`
- **비선형 구조**: `트리, 그래프`

### 스택(Stack)
데이터의 입출력이 한쪽에서만 일어나는 구조. 후입선출(LIFO)
데이터의 입출력이 한쪽에서만 일어나는 구조 후입선출(LIFO) 방식이다.
- **TOP**: 가장 마지막에 삽입된 데이터가 저장된 위치
- **PUSH**: 스택에 값을 삽입
- **POP**: 스택에서 값을 추출
- 스택의 크기를 초과하면 `overflow`, 스택의 값이 0보다 작아지게 되면 `underflow`
- 프로그램의 함수(서브 루틴) 호출, 깊이 우선 탐색, 재귀 호출, Liner List, Post-fix 등에 사용됨
- 0-주소 명령어 방식에서 활용

### 수식 표기법
피연산자와 연산자를 배치, 나열하는 방법
- **전위식(Per-fix)**: 연산자가 피연산자들의 앞(왼쪽)에 위치
- **중위식(In-fix)**: 연산자가 피연산자들의 중간에 위치
- **후위식(Post-fix)**: 연산자가 피연산자들의 뒤(오른쪽)에 위치
- 연산 우선순위에 맞춰 괄호로 묶음 다음, 제일 바깥쪽 괄호부터 연산자를 처리
- 연산자는 괄호 내의 범위에서만 옮겨짐
- 연산자를 묶을 땐 기본적으로 왼 → 오 순서대로 

#### 수식 표기법 예제1
중위식을 전위식과 후위식으로 표현하시오. `(A-B) × C + D`

- **✔️전위식**: `+×-ABCD`
- **✔️ ️후위식** `AB-C×D+`

> 중위식을 모두 괄호로 묶어준다. `(A-B) × C + D` → `(((A-B)×C)+D)`
> - 전위식: 괄호 안에 있는 연산자를 모두 왼쪽으로 이동 → `(+(×(-AB)C)D)`
> - 후위식: 괄호 안에 있는 연산자를 모두 오른쪽으로 이동 → `(((AB-)C×)D-)`
> - 괄호를 제거

#### 수식 표기법 예제2
전위식을 중위식으로 표현하시오. `×+AB-CD`
- ✔️ `(A+B)×(C-D)`

> `×+AB-CD` → `(×(+AB)(-CD))`
> - 연산자를 피연산자 중간으로 이동 → `((A+B)×(C-D))`

#### 수식 표기법 예제3
후위식을 중위식으로 표현하시오. `ABC×+D-`
- ✔️ `A+B×C-D`

> `ABC×+D-` → `((A(BC×)+)D-)`
> - 연산자를 피연산자 중간으로 이동 → `((A+(B×C))-D)`

### 큐(Queue)
데이터의 입출력이 서로 다른 방향에서 일어나는 구조. 선입선출(FIFO)
- **Rear**: 가장 마지막에 삽입된 데이터의 위치 (삽입 될 때마다 +1)
- **Front**: 가장 처음에 삽입된 데이터의 위치 혹은 가장 첫 번째 원소의 바로 앞 인덱스(삭제 될 때마다 +1)
- 데이터가 삭제될 수록 Front 값이 증가하므로 저장된 데이터를 다시 앞쪽으로 옮겨줘야 한다.
- 프린터 스풀이나 입출력 버퍼와 같은 대기 행렬에 적합

### 데크(Deque)
데이터의 입출력이 양쪽 모두에서 일어나는 구조(양방향 큐)
- 각각의 포인터(Left, Right)가 데이터 삽입, 삭제에 따라 1씩 증감
- **입력 제한(Scroll)**: 출력은 양쪽에서 가능하지만 입력은 한쪽에서만 가능
- **출력 제한(Shelf)**: 입력은 양쪽에서 가능하지만 출력은 한쪽에서만 가능

### 배열(Array)
동일한 자료형의 데이터들을 메모리 상의 연속된 공간에 저장하는 자료구조
- 인덱스를 사용하여 요소에 직접 전근하며, 인덱스는 항상 0부터 시작
- 한 번 정해진 크기는 변경할 수 없음
- 데이터 삽입/삭제 시 데이터를 이동시켜야 하므로 효율이 떨어짐.

### 선형(Linear) 리스트
데이터가 논리적으로 일렬로 연결된 구조.
1. **연속 리스트(Contiguous List=배열 기반)**
   - 메모리의 연속된 공간에 데이터를 배치 
   - 조회가 매우 빠르나 삽입/삭제 시 오버헤드가 발생할 수 있음
2. **연결 리스트(Linked List=포인터 기반)**
   - 데이터들이 메모리의 임의의 공간에 흩어져 있고, 포인터로 연결됨 
   - 삽입과 삭제 시 포인터만 바꿔주면 됨. 
   - 특정 요소를 찾으려면 처음부터 링크를 따라갸아 함 

### 트리(Tree)
데이터를 1:N의 계층 구조로 표현하는 자료구조
- 자식 노드가 최대 2개인 노드들로만 구성된 것은 이진 트리라고 한다.

| 용어                         | 설명                                        |
|----------------------------|-------------------------------------------|
| **노드(Node, Vertex)**       | 트리의 구성 요소로 데이터를 저장하는 기억 공간                |
| **간선(Edge, Branch)**       | 노드들을 연결하는 선 또는 가지                         |
| **근 노드(Root Node)**        | 최상위 노드 (유일함. 시작 노드)                       |
| **부모 노드(Parent Node)**     | 특정 노드의 상위 노드                              |
| **자식 노드(Child Node)**      | 특정 노드의 하위 노드                              |
| **형제 노드(Sibling Node)**    | 동일한 부모 노드를 가지는 노드                         |
| **단말 노드(Leaf Node)**       | 최하위 노드(자식 없음. 외부 노드라고도 함)                 |
| **내부 노드(Internal Node)**   | 즉 하나 이상의 자식 노드를 가진 노드 (단말 노드가 아닌 모든 노드)   |
| **차수(Degree)**             | 특정 노드에서 뻗어 나가는 자식 노드의 수                   |
| **트리의 차수(Degree of Tree)** | 가장 큰 차수를 가진 노드의 차수                        |
| **레벨(Level)**              | 트리의 각 층에 번호를 매긴 것. 루트 노드의 레벨은 보통 1 (또는 0) |
| **깊이/높이(Depth/Height)**    | 트리가 가질 수 있는 최대 레벨(또는 최대 깊이)을 의미           |
| **크기(Size)**               | 자신을 포함한 모든 자식 노드 개수                       |
| **서브 트리(Subtree)**         | 루트 노드를 제외한 나머지 노드들로 구성된 작은 트리들            |

> - 트리의 높이: 루트 노드와 단말 노드까지의 거리(간선의 개수)
> - 노드의 깊이: 해당 노드의 상위(부모) 노드 개수

### 트리의 순회
- **중위 순회(In-Order)**: 좌측 자식 → 부모 → 우측 자식 <u>(좌측을 모두 방문하고 루트 노드를 방문)</u>
- **전위 순회(Pre-Order)**: 부모 → 좌측 자식 → 우측 자식 <u>(루트 노드부터 방문)</u>
- **후위 순회(Post-Order)**: 좌측 자식 → 우측 자식 → 부모 <u>(루트 노드를 마지막에 방문)</u>

### 그래프(Graph)
노드를 N:M의 구조로 연결하여 데이터 간의 관계를 표현하는 자료 구조. 노드 간 2개 이상의 경로 설정이 가능한 네트워크 모델이다.

| 용어                     | 설명                    |
| ---------------------- | --------------------- |
| **정점 (Vertex, Node)**  | 데이터가 담기는 지점           |
| **간선 (Edge, Link)**    | 정점과 정점을 잇는 선          |
| **인접 (Adjacent)**      | 두 정점이 간선으로 직접 연결된 상태  |
| **부수 (Incident)**      | 간선이 특정 정점에 연결되어 있는 관계 |
| **사이클(Cycle)**         | 시작과 종료의 정점이 동일한 경우    |
| **경로 길이(Path Length)** | 경로를 구ㅎ성하는 데 사용된 간선의 수 |

1. **방향 그래프**
   - 간선에 방향성이 존재하여 한 방향으로 진행되는 그래프 
   - 정점 A에서 B로 갈 수 있는 형태는 <A,B>로 표현
   - - **진입 차수(In-Degree)**: 방향 그래프에서 외부에서 오는 간선의 수(내차수)
   - **진출 차수(Out-Degree)**: 방향 그래프에서 외부로 향하는 간선의 수(외차수)
   - **최대 간선 수**: $n(n-1)$
2. **무방향 그래프**
   - 간선에 방향성 없이 양방향으로 진행되는 그래프 
   - 정점 A에서 B로 갈 수 있는 형태는 (A,B) 혹은 (B,A)로 표현
   - **최대 간선 수**: $n(n-1) / 2$ (양방향이므로 2를 나눠줌)

### 그래프의 운행
- **깊이 우선 탐색(DFS)**:한 방향으로 갈 수 있을 때까지 깊게 파고들다가, 더 이상 갈 곳이 없으면 가장 마지막에 만났던 갈림길로 돌아와 다른 방향을 탐색하는 방식
- **너비 우선 탐색(BFS)**: 시작 정점으로부터 가까운 정점들을 먼저 차례대로 방문하고, 그다음 멀리 떨어진 정점들을 방문하는 방식
- 기본적으로 왼쪽부터 방문한다.

#### 그래프 운행 예제
다음 그래프에서 정점 A를 선택하여 깊이 우선 탐색으로 운행한 결과는?
![img.png](graphex1.png)

- **✔️ 깊이 우선 탐색**: A→B→E→F→G→C→D
- **너비 우선 탐색**: A→B→C→D→E→F→G 

> 깊이 우선 탐색은 반드시 연결된 선을 따라가야함. 
> 더 이상 갈 곳이 없으면 부모로 돌아가서 다시 탐색(백트래킹). 이때 방문했던 노드는 다시 적지 않는다 

> 너비 우선 탐색은 인접해 있는 같은 레벨의 노드를 모두 방문하고, 다음 레벨로 넘어가서 동일하게 진행
> A와 인접한 레벨은 B,C,D 이들을 다 방문하고 다음 B와 연결된 E와 C와 연결된 F를 방문. 마지막으로 F와 연결된 G를 방문

### 알고리즘 설계 기법
- **동적 계획법(Dynamic Programming)**: 작은 문제의 해답을 메모리에 저장해 두었다가 큰 문제를 풀 때 재사용하여 중복 계산을 방지
- **탐욕적 알고리즘(Greedy Algorithm)**: 매 순간 최적이라고 생각되는 선택을 하여 최종 해답에 도달하는 방식
- **분할 정복법(Divide and Conquer)**: 문제를 작은 단위로 나눈 뒤 각각 해결하고 결과를 합치는 방식
- **재귀적 알고리즘(Recursive Algorithm)**: 함수가 문제의 답을 구하기 위해 자기 자신을 다시 호출하여 문제를 해결하는 기법
- **근사 알고리즘(Approximation Algorithm)**: 최적의 해를 찾는 데 시간이 오래 걸리는 문제에 대해 최적에 가까운 값을 빠르게 구하는 기법
- **퇴각 검색법(Backtracking)**: 해를 찾는 과정에서 막히면 되돌아가서 다시 해를 찾는 기법. 주로 재귀로 구현한다.
- **분기 한정법(Branch and Bound)**: 백트래킹과 유사하지만, 하한선/상한선을 계산하여 불필요한 경로를 더 빠르게 차단한다.

### 빅오 표기법

| 증가 함수               | 데이터($n$) 증가에 따른 변화        | 알고리즘                   |
| ------------------- |---------------------------|------------------------|
| $O(1)$              | 데이터 양과 무관하게 즉시 완료         | 해시 테이블, 배열의 인덱스 참조, 스택 |
| $O(\log n)$        | 연산마다 탐색 범위가 절반씩 줄어듦       | 이분 탐색, 이진 트리 탐색        |
| $O(n)$              | 데이터 개수와 연산 횟수가 정비례        | 순차 탐색                  |
| $O$($n$ $\log$ $n)$ | 데이터 양 × 로그 배율만큼 연산 횟수가 증가 | 퀵 정렬, 힙 정렬, 병합 정렬      |
| $O(n^2)$            | 데이터의 제곱만큼 연산 발생           | 버블 정렬, 삽입 정렬, 선택 정렬    |
| $O(2^n)$            | 데이터가 1개 늘어날 때마다 연산량 2배 증가 | 재귀 호출                  |

- 힙 정렬, 병합 정렬은 최악의 경우에도 항상 $O(n \log n)$
- 퀵 정렬의 최악 시간 복잡도는 $O(n^2)$
- 삽입, 버블, 병합 정렬은 중복된 값의 순서가 유지됨

### 선형(Linear) 탐색
검색 대상을 처음부터 순차적으로 비교하여 검색. 데이터의 개수나 정렬 여부를 알지 못해도 사용 가능.

### 이분(binary) 탐색
검색 대상을 절반으로 나누어 탐색.
- **선행 작업**: 데이터 정렬
- **중간 위치**: (시작 위치 + 끝 위치) / 2 (소수점 발생 시 버림)
- 탐색 범위 조절 
  - 중간값 > 찾고자 하는 값: 끝위치를 `(중간 위치 -1)`로 변경
  - 중간값 < 찾고자 하는 값: 시작 위치를 `(중간 위치 + 1)`로 변경

#### 이분 탐색 예제
[10, 20, 30, 40, 50, 60, 70, 80, 90] 에서 '70'을 찾기 위해 이분 탐색을 수행할 때, 필요한 비교 횟수는?

- **✔️ 비교 횟수: 2**

> 인덱스가 1번수터 시작한다고 가정했을 때, 중간 위치는 $(1+9)/2=5$ 이다. <br/>
> 중간값인 50과 찾으려는 값인 70을 비교하면, 70이 더 크므로 시작 위치를 6(중간 위치 +1)로 변경 <br/>
> 끝 위치는 9로 고정된 상태에서 다시 중간 위치를 계산하면 $(6+9)/2=7.5$가 나온다. <br/>
> 소수점을 버리면 중간 위치는 7이 되며, 해당 위치의 값이 70이므로 두 번만에 값을 찾음

### 선택(Selection) 정렬
기준값으로 선택된 데이터를 나머지 데이터와 비교하는 정렬 방식
- 오름차순 정렬 시: 최솟값을 기준
- 내림차순 정렬 시: 최대값을 기준
- 한 회전이 끝날 때까지 전체를 탐색하여 기준값을 확정한 뒤, 딱 한 번만 교환을 수행

#### 선택 정렬 예제
[8, 3, 4, 9, 7] 오름차순으로 정렬하고자 할 때, 1회전 수행 결과는?

- **✔️ 1회전: <u>3</u>, 8, 4, 9, 7**
- 2회전: 3, <u>4</u>, 8, 9, 7
- 3회전: 3, 4, <u>7</u>, 9, 8
- 4회전: 3, 4, 7, <u>8</u>, 9

### 버블 정렬
인접한 두 데이터를 비교하여 정렬 조건에 따라 자리를 바꾸며 이동
- 오름차순 정렬 시: `왼쪽 데이터 > 오른쪽 데이터` 일 때 자리를 바꿈. 한 회전이 끝나면 가장 큰 값이 맨 뒤로 이동
- 내림차순 정렬 시: `왼쪽 데이터 < 오른쪽 데이터` 일 때 자리를 바꿈. 한 회전이 끝나면 가장 작은 값이 맨 뒤로 이동
- 데이터가 하나식 뒤로 밀려나는 모습이 거품이 올라오는 것과 비슷하여 버블 정렬이라 부르며, 한 회전마다 맨 뒤의 자리가 고정된다.

#### 버블 정렬 예제
[9, 6, 7, 3, 5] 오름차순으로 정렬할 경우 PASS 3의 결과는?

- PASS 1: 6, 7, 3, 5, <u>9</u>
- PASS 2: 6, 3, 5, <u>7</u>, 9
- **✔️ PASS 3: 3, 5, <u>6</u>, 7, 9**

### 삽입 정렬
이미 정렬된 앞부분의 데이터들과 비교하여 자신의 위치를 찾아 삽입하는 방식. 두 번째 데이터부터 정렬을 시작 
- 오름차순 정렬 시: 선택한 데이터가 앞의 데이터보다 작으면 앞의 데이터를 뒤로 밀고, 적절한 위치에 데이터를 삽입
- 내림차순 정렬 시: 선택한 데이터가 앞의 데이터보다 크면 위치를 찾아 삽입
- 한 회전이 끝날 때마다 앞부분의 데이터들이 정렬된 상태를 유지

#### 삽입 정렬 예제
[64, 28, 33, 76, 55, 12, 43] 오름차순으로 정렬할 때 PASS 2의 결과는?

- PASS 1: <u>28</u>, 64, 33, 76, 55, 12, 43 
- **✔️ PASS 2: 28, <u>33</u>, 64, 76, 55, 12, 43**
- PASS 3: 28, 33, 64, <u>76</u>, 55, 12, 43 (76은 좌측의 정렬된 데이터보다 크므로 자리 유지)
- PASS 4: 28, 33, <u>55</u>, 64, 76, 12, 43
- PASS 5: <u>12</u>, 28, 33, 55, 64, 76, 43
- PASS 6: 12, 28, 33, <u>43</u>, 55, 64, 76 

### 힙 정렬
정렬 대상을 완전 이진 트리 형태로 만들어 정렬하는 방식
- 모든 시간 복잡도는 $O(n \log n)$

### 퀵 정렬
분할 정복 알고리즘을 적용한 정렬 기법으로 매우 빠른 시간 복잡도를 가진다.

### 해시 함수의 종류
- **제산법 (Division)**: 키 값을 소수로 나눈 나머지를 주소로 결정
- **폴딩법 (Folding)**: 키를 여러 부분으로 나눈 후, 각 부분을 더하거나 XOR 하여 주소 결정
- **제곱법 (Square)**: 키 값을 제곱한 후, 결과의 중간 부분을 주소로 사용
- **숫자 분석법 (Digit Analysis)**: 키 값들의 각 자릿수 분포를 분석하여 고른 분포의 자리를 선택
- **기수 변환법 (Radix Conversion)**: 키 숫자의 진수를 다른 진수로 변환하여 주소로 사용
- **무작위법 (Random)**: 난수를 발생시켜 주소를 결정

### 해시 충돌(Collision)
서로 다른 키 값이 해시 함수에 의해 동일한 홈 주소로 계산되는 현상
- **버킷(Bucket)**: 하나의 주소 안에 여러 개의 레코드를 저장할 수 있는 공간
- **슬롯(Slot)**: 버킷 내에서 하나의 레코드를 저장할 수 있는 단위
- **충돌 해결 방법**:
  1. **개방 주소법**: 충돌 시 비어있는 다른 버킷을 찾아 저장
  2. **체이닝**: 같은 주소에 데이터를 연결 리스트로 줄줄이 연결하여 저장
